{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import compress_json\n",
    "from glob import glob\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from humanize import naturaldelta\n",
    "from tqdm.auto import tqdm, trange\n",
    "from time import perf_counter, sleep\n",
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "from matplotlib.patches import Ellipse\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import humanize \n",
    "\n",
    "def xformat_func(value, tick_number):\n",
    "    if value == 0:\n",
    "        return \"0s\"\n",
    "    if value < 1e-9:\n",
    "        return r\"${:.2f}ps$\".format(value * 1e12)\n",
    "    if value < 1e-6:\n",
    "        return r\"${:.2f}ns$\".format(value * 1e9)\n",
    "    if value < 1e-3:\n",
    "        return r\"${:.2f}\\mu s$\".format(value * 1e6)\n",
    "    if value < 1:\n",
    "        return r\"${:.2f}ms$\".format(value * 1e3)\n",
    "    if value < 60:\n",
    "        return r\"${:.2f}s$\".format(value)\n",
    "    if value < 3600:\n",
    "        return r\"${:.2f}m$\".format(value / 60)\n",
    "    \n",
    "    return r\"${:.2f}h$\".format(value / 3600)\n",
    "\n",
    "def yformat_func(value, tick_number):\n",
    "    return humanize.naturalsize(value * (1000**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    path\n",
    "    for path in glob('./graphs/results/**/*.csv', recursive=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.DataFrame([\n",
    "    compress_json.load(report_path)\n",
    "    for report_path in glob(\"./graphs/**/report.json\", recursive=True)\n",
    "]).astype({\n",
    "    \"degree_mean\":float,\n",
    "    \"density\":float,\n",
    "    \"nodes_number\":int,\n",
    "    \"undirected_edges_number\":int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a715dc6068c48e28421053b77f4a327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading benchmarks', max=836.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crashed = {}\n",
    "result = pd.DataFrame()\n",
    "for file in tqdm(files, desc=\"Loading benchmarks\"):\n",
    "    # From the path extract the infos\n",
    "    *_, graph, library, task = file.split(\"/\")\n",
    "    task = task.split(\".\")[0]\n",
    "    # Load the file\n",
    "    df = pd.read_csv(file, usecols=[0,1], dtype={\n",
    "        \"time\":float,\n",
    "        \"memory\":float\n",
    "    })\n",
    "    df.columns = [\"time\", \"memory\"]\n",
    "    df[\"name\"] = graph\n",
    "    df[\"library\"] = library\n",
    "    df[\"task\"] = task\n",
    "    \n",
    "    # Check if the experiment was killed\n",
    "    last_row = df.iloc[-1]\n",
    "    if last_row.time == 0 and last_row.memory== 0:\n",
    "        exec_type = \"ok\"\n",
    "        df = df.head(-1)\n",
    "    else:\n",
    "        crashed[(library, task)] = True\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Update the global results\n",
    "    result = pd.concat([result, df])\n",
    "\n",
    "result=result.merge(reports, on=[\"name\"])\n",
    "max_result = result.groupby([\"name\", \"library\", \"task\"]).max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b112eb914f8a4feca562c69297b9b4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading benchmarks', max=836.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "complete_result = pd.DataFrame()\n",
    "for file in tqdm(files, desc=\"Loading benchmarks\"):\n",
    "    # From the path extract the infos\n",
    "    *_, graph, library, task = file.split(\"/\")\n",
    "    task = task.split(\".\")[0]\n",
    "    # Load the file\n",
    "    df = pd.read_csv(file, usecols=[0,1], dtype={\n",
    "        \"time\":float,\n",
    "        \"memory\":float\n",
    "    })\n",
    "    df.columns = [\"time\", \"memory\"]\n",
    "    df[\"name\"] = graph\n",
    "    df[\"library\"] = library\n",
    "    df[\"task\"] = task    \n",
    "    \n",
    "    # Update the global results\n",
    "    complete_result = pd.concat([complete_result, df])\n",
    "\n",
    "complete_result=complete_result.merge(reports, on=[\"name\"])\n",
    "complete_max_result = complete_result.groupby([\"name\", \"library\", \"task\"]).max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-196801e37bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwilcoxon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmetric1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmetric2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/scipy/stats/morestats.py\u001b[0m in \u001b[0;36mwilcoxon\u001b[0;34m(x, y, zero_method, correction, alternative)\u001b[0m\n\u001b[1;32m   2863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The samples x and y must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2865\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mzero_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"wilcox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pratt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "libraries = [\n",
    "    library\n",
    "    for library in complete_max_result.library.unique()\n",
    "    # Filtering GraphEmbedding since it does not have yet the necessary datapoints\n",
    "    if library != \"GraphEmbedding\"\n",
    "]\n",
    "\n",
    "possible_results = [\"win\", \"tie\", \"loss\"]\n",
    "tasks = [\"load_graph\", \"first_order_walk\", \"second_order_walk\"]\n",
    "metrics = [\"time\", \"memory\"]\n",
    "\n",
    "win_tie_loss = {\n",
    "    metric: {}\n",
    "    for metric in metrics\n",
    "}\n",
    "\n",
    "for task in tasks:\n",
    "    for i, library1 in enumerate(libraries):\n",
    "        for library2 in libraries[i+1:]:\n",
    "            for metric in metrics:\n",
    "                metric1 = complete_max_result[\n",
    "                    (complete_max_result.library == library1) &\n",
    "                    (complete_max_result.task == task)\n",
    "                ].sort_values(by=[\"nodes_number\"])[metric].values.flatten()\n",
    "                metric2 = complete_max_result[\n",
    "                    (complete_max_result.library == library2) &\n",
    "                    (complete_max_result.task == task)\n",
    "                ].sort_values(by=[\"nodes_number\"])[metric].values.flatten()\n",
    "                wtl = win_tie_loss[metric]\n",
    "                if len(metric2)==0:\n",
    "                    for result in possible_results:\n",
    "                        key1 = (library2, task, result)\n",
    "                        wtl[key1] = wtl.get(key1, np.nan)\n",
    "                if len(metric1)==0:\n",
    "                    for result in possible_results:\n",
    "                        key1 = (library1, task, result)\n",
    "                        wtl[key1] = wtl.get(key1, np.nan)\n",
    "                if len(metric1)==0 or len(metric2)==0:\n",
    "                    continue\n",
    "                _, p_value = wilcoxon(metric1, metric2)\n",
    "                if p_value < 0.01:\n",
    "                    if metric1.mean() < metric2.mean():\n",
    "                        key1 = (library1, task, \"win\")\n",
    "                        key2 = (library2, task, \"loss\")\n",
    "                        wtl[key1] = wtl.get(key1, 0) + 1\n",
    "                        wtl[key2] = wtl.get(key2, 0) + 1\n",
    "                    else: \n",
    "                        key1 = (library1, task, \"loss\")\n",
    "                        key2 = (library2, task, \"win\")\n",
    "                        wtl[key1] = wtl.get(key1, 0) + 1\n",
    "                        wtl[key2] = wtl.get(key2, 0) + 1\n",
    "                else:\n",
    "                    key1 = (library1, task, \"tie\")\n",
    "                    key2 = (library2, task, \"tie\")\n",
    "                    wtl[key1] = wtl.get(key1, 0) + 1\n",
    "                    wtl[key2] = wtl.get(key2, 0) + 1\n",
    "\n",
    "tables = {\n",
    "    metric: pd.DataFrame({\n",
    "        (sanitize_ml_labels(metric), sanitize_ml_labels(task), sanitize_ml_labels(result)): {\n",
    "            library: win_tie_loss[metric].get((library, task, result), 0)\n",
    "            for library in libraries\n",
    "        }\n",
    "        for task in tasks\n",
    "        for result in possible_results\n",
    "    })\n",
    "    for metric in metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[\"memory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"all_reports.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"load_graph\", \"first_order_walk\", \"second_order_walk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.patheffects as PathEffects\n",
    "fp = FontProperties(fname=\"otfs/Font Awesome 5 Free-Solid-900.otf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "colors = dict(list(zip(result.library.unique(), cmap.colors)))\n",
    "graphs = max_result.name.unique()\n",
    "libraries = max_result.library.unique()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(tasks), nrows=4, figsize=(6*len(tasks), 20), squeeze=False)\n",
    "\n",
    "for library in libraries:\n",
    "    for i, task in enumerate(tasks):\n",
    "        data = max_result[\n",
    "            (max_result.library == library) &\n",
    "            (max_result.task == task)\n",
    "        ]\n",
    "        if data.empty:\n",
    "            continue\n",
    "        pos = 0\n",
    "        for k, number in enumerate((\"undirected_edges_number\", \"nodes_number\")):\n",
    "            for j, (column, format_func) in enumerate(((\"time\", xformat_func), (\"memory\", yformat_func))):\n",
    "                axis = axes[pos, i]\n",
    "                pos+=1\n",
    "                axis.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "                sorted_data = data.sort_values(by=[number])\n",
    "                axis.plot(sorted_data[number], sorted_data[column], label=library, c=colors[library])\n",
    "                axis.plot(sorted_data[number], sorted_data[column], '.', c=colors[library])\n",
    "                if (library, task) in crashed:\n",
    "                    x, y = sorted_data.iloc[-1][[number, column]].values\n",
    "                    txt = axis.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        \"\\uf54c\",\n",
    "                        c=colors[library],\n",
    "                        fontproperties=fp,\n",
    "                        fontsize=18\n",
    "                    )\n",
    "                    txt.set_path_effects([\n",
    "                        PathEffects.withStroke(\n",
    "                            linewidth=6,\n",
    "                            foreground=colors[library],\n",
    "                        ),\n",
    "                        PathEffects.withStroke(\n",
    "                            linewidth=5,\n",
    "                            foreground='w',\n",
    "                            alpha=0.9\n",
    "                        )\n",
    "                    ])\n",
    "                axis.set_ylabel(sanitize_ml_labels(column))\n",
    "                axis.set_xlabel(sanitize_ml_labels(number))\n",
    "                axis.set_xscale(\"log\")\n",
    "                axis.set_yscale(\"log\")\n",
    "                axis.set_title(sanitize_ml_labels(task))\n",
    "                axis.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "                axis.legend(loc=\"lower right\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "colors = dict(list(zip(result.library.unique(), cmap.colors)))\n",
    "graphs = max_result.name.unique()\n",
    "libraries = max_result.library.unique()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(tasks), nrows=2, figsize=(6*len(tasks), 10), squeeze=False)\n",
    "\n",
    "for library in libraries:\n",
    "    for i, task in enumerate(tasks):\n",
    "        data = max_result[\n",
    "            (max_result.library == library) &\n",
    "            (max_result.task == task)\n",
    "        ]\n",
    "        if data.empty:\n",
    "            continue\n",
    "        for k, number in enumerate((\"undirected_edges_number\", \"nodes_number\")):\n",
    "            axis = axes[k, i]\n",
    "            axis.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "            sorted_data = data.sort_values(by=[\"time\"])\n",
    "            axis.plot(sorted_data[\"time\"], sorted_data[\"memory\"], label=library, c=colors[library])\n",
    "            axis.set_ylabel(sanitize_ml_labels(\"Memory\"))\n",
    "            axis.set_xlabel(sanitize_ml_labels(\"Time\"))\n",
    "            axis.set_xscale(\"log\")\n",
    "            axis.set_yscale(\"log\")\n",
    "            axis.set_title(sanitize_ml_labels(task))\n",
    "            axis.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "            axis.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot RAM over time for each task and each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_without_duplicate_labels(fig, axes, **kwargs):\n",
    "    labels_set = set()\n",
    "    uniques = []\n",
    "    for row in axes:\n",
    "        for ax in row:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            axis_unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "            for (h, l) in axis_unique:\n",
    "                if l not in labels_set:\n",
    "                    labels_set.add(l)\n",
    "                    uniques.append((h, l))\n",
    "    ax.legend(*zip(*uniques), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols=len(result.task.unique())\n",
    "nrows=len(result.name.unique())\n",
    "    \n",
    "\n",
    "for log in [True, False]:\n",
    "    fig, axes = plt.subplots(\n",
    "        dpi=150,\n",
    "        ncols=ncols,\n",
    "        nrows=nrows,\n",
    "        squeeze=False,\n",
    "        figsize=(5*ncols, 4*nrows)\n",
    "    )\n",
    "    for graph, sub_axes in zip(result.name.unique(), axes):\n",
    "        for task, axis in zip(tasks, sub_axes):\n",
    "            all_data = result[(result.name==graph) & (result.task==task)]\n",
    "            max_y = 10**np.ceil(np.log10(all_data.memory.max()))\n",
    "            min_y = all_data.memory.min()\n",
    "            if min_y < 0.0001:\n",
    "                min_y = 0.0001\n",
    "                \n",
    "            min_y = 10**np.floor(np.log10(min_y))\n",
    "            max_x = all_data.time.max()\n",
    "            min_x = all_data.time.min()\n",
    "            for library in result.library.unique():\n",
    "                # get the data for this triple (graph, task, library)\n",
    "                filtered = all_data[(all_data.library==library)]\n",
    "                if len(filtered):\n",
    "                    # Plot the graph\n",
    "                    axis.plot(filtered.time, filtered.memory, label=sanitize_ml_labels(library), c=colors[library])\n",
    "                    x, y = filtered.time.iloc[-1], filtered.memory.iloc[-1]\n",
    "                    # add the termination marker\n",
    "                    exec_type = execs_type[graph][library][task]\n",
    "                    if exec_type == \"killed\":\n",
    "                        axis.plot([x], [y], marker=\"x\", c=colors[library], markersize=10)\n",
    "                    elif exec_type == \"exception\":\n",
    "                        axis.plot([x], [y], marker=\"^\", c=colors[library])\n",
    "                    else:\n",
    "                        axis.plot([x], [y], marker=\".\", c=colors[library])\n",
    "                    # Draw the finish line\n",
    "                    axis.plot([x, x], [min_y, y], \"--\", alpha=0.5, c=colors[library])\n",
    "                    axis.plot([min_x, x], [y, y], \"--\", alpha=0.5, c=colors[library])\n",
    "            if log:                    \n",
    "                if not (np.isnan(min_y) or np.isnan(max_y)):\n",
    "                    axis.set_ylim([min_y, max_y*1.1])\n",
    "                axis.set_yscale('log')\n",
    "                axis.set_xscale('log')\n",
    "                axis.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "            \n",
    "            axis.set_xlabel(\"Time\")\n",
    "            axis.set_ylabel(\"RAM used\")\n",
    "            axis.xaxis.set_tick_params(rotation=-20)\n",
    "            axis.xaxis.set_major_formatter(plt.FuncFormatter(xformat_func))\n",
    "            axis.yaxis.set_major_formatter(plt.FuncFormatter(yformat_func))\n",
    "            axis.set_title(\"{graph}\\n{task}\".format(\n",
    "                graph=graph,\n",
    "                task=sanitize_ml_labels(task)\n",
    "            ))\n",
    "            \n",
    "                \n",
    "    legend_without_duplicate_labels(fig, axes, title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "    fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_reports = {\n",
    "    report_path.split(\"/\")[2]: open(report_path, \"r\").read()\n",
    "    for report_path in glob(\"./graphs/**/report.txt\", recursive=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_pattern = re.compile(\"\\d+(?:\\.\\d)*\\d*\")\n",
    "for graph, text in textual_reports.items():\n",
    "    for number in sorted(re.findall(numbers_pattern, text),  reverse=True):\n",
    "        textual_reports[graph] = textual_reports[graph].replace(\n",
    "            \" {}\".format(number),\n",
    "            \" \\({}\\)\".format(number)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reports.txt\", \"w\") as f:\n",
    "    for graph, text in textual_reports.items():\n",
    "        corrected = graph.replace(\"_\", \"\\_\").capitalize()\n",
    "        f.write(\"\\\\subsection{{{graph}}}\\n\".format(graph=corrected))\n",
    "        f.write(text.replace(\"_\", \"\\_\"))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
