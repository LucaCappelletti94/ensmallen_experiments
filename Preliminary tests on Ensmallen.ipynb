{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from ensmallen_graph import EnsmallenGraph\n",
    "from ensmallen_experiments import MeasureResources\n",
    "import compress_json\n",
    "from tqdm.auto import tqdm, trange\n",
    "import os\n",
    "from time import perf_counter, sleep\n",
    "from humanize import naturaldelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "import networkx as nx\n",
    "from glob import glob\n",
    "from node2vec import Node2Vec\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to load the graphs using each library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_ensmallen(edge_path:str):\n",
    "    \"\"\"Load graph object using EnsmallenGraph.\"\"\"\n",
    "    return EnsmallenGraph.from_csv(\n",
    "        edge_path,\n",
    "        sources_column_number=0,\n",
    "        destinations_column_number=1,\n",
    "        directed=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_networkx(edge_path:str):\n",
    "    \"\"\"Load graph object using NetworkX.\"\"\"\n",
    "    return nx.read_edgelist(\n",
    "        edge_path,\n",
    "        data=False,\n",
    "        delimiter=\"\\t\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to compute first and second order walks in each library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensmallen_first_order_walks(graph: EnsmallenGraph, walk_length:int, num_walks:int, **kwargs):\n",
    "    \"\"\"Execute uniform first order walks using Networkx-based node2vec walker.\"\"\"\n",
    "    return graph.complete_walks(length=walk_length, iterations=num_walks)\n",
    "\n",
    "def ensmallen_second_order_walks(graph: EnsmallenGraph, p:float, q:float, walk_length:int, num_walks:int):\n",
    "    \"\"\"Execute uniform second order walks using Networkx-based node2vec walker.\"\"\"\n",
    "    return graph.complete_walks(length=walk_length, iterations=num_walks, return_weight=1/p, explore_weight=1/q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2vec_first_order_walks(graph: nx.Graph, walk_length:int, num_walks:int, **kwargs):\n",
    "    \"\"\"Execute uniform first order walks using Networkx-based node2vec walker.\"\"\"\n",
    "    return Node2Vec(graph, walk_length=walk_length, num_walks=num_walks, workers=cpu_count()).walks\n",
    "\n",
    "def node2vec_second_order_walks(graph: nx.Graph, p:float, q:float, walk_length:int, num_walks:int):\n",
    "    \"\"\"Execute uniform second order walks using Networkx-based node2vec walker.\"\"\"\n",
    "    return Node2Vec(graph, walk_length=walk_length, num_walks=num_walks, workers=cpu_count(), p=p, q=q).walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path(data:Dict, root:str):\n",
    "    \"\"\"Build path to edge file from given metadata.\"\"\"\n",
    "    return os.path.join(root, data[\"folder_name\"], \"sanitized.tsv\")\n",
    "\n",
    "def get_graph_report(data:Dict, root:str)->Dict:\n",
    "    \"\"\"Build path to edge file from given metadata.\"\"\"\n",
    "    return compress_json.load(os.path.join(root, data[\"folder_name\"], \"report.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameters for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = 1\n",
    "graph_root = \"graphs\"\n",
    "walk_parameters = dict(\n",
    "    walk_length=30,\n",
    "    num_walks=1, # This is iterations in ensmallen.\n",
    "    p=2,\n",
    "    q=2\n",
    ")\n",
    "\n",
    "libraries = {\n",
    "    \"ensmallen\":[\n",
    "        load_graph_ensmallen,\n",
    "        ensmallen_first_order_walks,\n",
    "        ensmallen_second_order_walks\n",
    "    ],\n",
    "    \"networkx\":[\n",
    "        load_graph_networkx,\n",
    "        node2vec_first_order_walks,\n",
    "        node2vec_second_order_walks\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(tracker:MeasureResources, metadata:Dict, walk_parameters:Dict, path:str):\n",
    "    with tracker(**metadata, step=\"builder\"):\n",
    "        graph = builder(path)\n",
    "    with tracker(**metadata, step=\"first_order_walks\"):\n",
    "        _ = first_order_walker(graph, **walk_parameters)\n",
    "    with tracker(**metadata, step=\"second_order_walks\"):\n",
    "        _ = second_order_walker(graph, **walk_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3b5f62f57c4303a51b1749bde97694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing benchmarks', max=1.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 16073/16073 [13:18<00:00, 20.12it/s]  \n",
      "/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lucacappelletti/ensmallen_experiments/ensmallen_experiments/measure_resources.py\", line 72, in resources_logger\n",
      "    sleep(refresh_delay)\n",
      "KeyboardInterrupt\n",
      "ERRO:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERRO:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 909, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 562, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 430, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-8-e07b0cdebf4c>\", line 5, in run_benchmark\n",
      "    _ = first_order_walker(graph, **walk_parameters)\n",
      "  File \"<ipython-input-5-4c26d3b51f8d>\", line 3, in node2vec_first_order_walks\n",
      "    return Node2Vec(graph, walk_length=walk_length, num_walks=num_walks, workers=cpu_count()).walks\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/node2vec/node2vec.py\", line 67, in __init__\n",
      "    self.walks = self._generate_walks()\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/node2vec/node2vec.py\", line 154, in _generate_walks\n",
      "    in enumerate(num_walks_lists, 1))\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1017, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 931, in retrieve\n",
      "    backend.abort_everything(ensure_ready=ensure_ready)\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 579, in abort_everything\n",
      "    self._workers.shutdown(kill_workers=True)\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1101, in shutdown\n",
      "    qmt.join()\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/lucacappelletti/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graphs_data = compress_json.load(\"graphs.json\")\n",
    "graphs_data = [graphs_data[0]]\n",
    "tracker = MeasureResources(verbose=False)\n",
    "\n",
    "for graph_data in tqdm(graphs_data, desc=\"Computing benchmarks\"):\n",
    "    name = graph_data[\"graph\"]\n",
    "    path = build_path(graph_data, graph_root)\n",
    "    report = get_graph_report(graph_data, graph_root)\n",
    "    for library, (builder, first_order_walker, second_order_walker) in libraries.items():\n",
    "        for loop in range(loops):\n",
    "            metadata = dict(\n",
    "                library=library,\n",
    "                graph=name,\n",
    "                loop=loop,\n",
    "                **report\n",
    "            )\n",
    "            run_benchmark(tracker, metadata, walk_parameters, path)\n",
    "\n",
    "results = tracker.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot RAM over time for each task and each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = results.graph.unique()\n",
    "libraries = results.library.unique()\n",
    "steps = results.step.unique()\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=len(steps),\n",
    "    nrows=len(graphs),\n",
    "    squeeze=False,\n",
    "    figsize=(5*len(steps), 4*len(graphs))\n",
    ")\n",
    "for graph, sub_axes in zip(graphs, axes):\n",
    "    for step, axis in zip(steps, sub_axes):\n",
    "        filtered = results[(results.graph==graph) & (results.step==step)]\n",
    "        axis.plot(filtered.delta, filtered.ram)\n",
    "        axis.set_xlabel(\"Seconds\")\n",
    "        axis.set_ylabel(\"RAM used\")\n",
    "        axis.set_title(graph)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
